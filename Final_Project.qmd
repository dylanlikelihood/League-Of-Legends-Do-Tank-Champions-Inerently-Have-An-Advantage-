---
title: "Propensity Score"
author: "Dylan Armbruster"
format: html
editor: visual
toc: True
---

# Introduction

Within the multi-player online platform League of Legends, champions are divided into distinct classes based upon abilities and purpose. One of those classes, Tanks, is perhaps the most likely class to bear community criticism and design scrutiny. Many players express frustration with playing against them. Citing that despite having diminished offense, they carry high starting endurance values which contribute to their undue strength, specifically where they remain strong despite still capable of inflicting real damage or utility.

This study seeks to answer a key question: Does Tank-class champion status causally increase win rate, after adjusting for baseline strength factors such as health, armor, and resistances? While simple comparisons of win rates between champion classes are confounded by factors, we apply a causal inference strategy to sidestep this challenge.

Specifically, we utilize Propensity Scores and Propensity Score Matching (PSM) to equate observed differences in champion statistics. PSM allows for a more accurate comparison by equating Tank and non-Tank champions on relevant covariates and permits us to estimate the Average Treatment Effect (ATE) of Tank status on game outcomes. Our objective is to split out the impact of class designation from other traits that independently affect win rate, thereby offering insight into whether or not Tanks are objectively privileged in competitive play.

All statistical analyses were performed using R (version 4.4.1), and a significance level of α = 0.05 was used for hypothesis testing. The hypothesis testing framework we decided to work with was the Neyman-Pearson Framework.

## Propensity Score

A propensity score is the conditional probability that a subject receives the treatment, given their observed characteristics (covariates) \[2, pg 201 - 202\]. Written as, $P(Z = 1 | x)$ where Z is the label for what treatment someone was assigned to. Formally, if we consider a group s with $n_{s}$ individuals, and each individual i has a treatment probability $\pi_{si}$, then the average probability across the group is:

$\lambda(x_{s}) = \frac{1}{n} \sum_{i = 1} \pi_{si}$

Here, $\lambda(x_s)$ is the overall chance that a randomly selected subject from stratum s receives the treatment. This value always lies between 0 and 1.

Think of a propensity score as a way to summarize, in one number, how likely someone is to get a treatment based on their background information. Instead of looking at all their details separately, we bundle it into a single probability. Imagine, "given who you are, there's a 70% chance you would have been treated." Now, we don't have to try and make comparable groups based on background information, now we can just focus on matching propensity score values. For more information on Propensity Scores, the standard paper is the influential paper by Rosenbaum and Rubin \[3\].

### Motivation

In the design of experiments, *randomization* plays a central role. It is different from *random sampling* in survey design. Randomization ensures that, on average, every subject has the same probability of being assigned to the treatment group. This process not only guarantees valid standard errors but also justifies the use of Fisher’s significance tests. Most importantly, randomization provides an unbiased estimate of the treatment effect.

Now, consider if we could replicate this mechanism in an observational study - creating groups of subjects who have similar probabilities of receiving treatment. Under a key assumption known as *strong ignorability*, we can approximate the conditions of a randomized experiment. If strong ignorability holds, the estimated Average Treatment Effect (ATE) from the observational study would also be unbiased.

Propensity Score Matching (PSM) is a somewhat controversial method. The debate arises from statisticians' concerns about its misuse, similar to criticisms of how confidence intervals or p-values are sometimes misinterpreted, particularly in fields like epidemiology. Some critics argue that PSM should be abandoned altogether, with King et al. (2019) \[4\] being a key reference for this stance. For a balanced perspective, Senn et al. (2007) \[5\] offers a less critical comparison between PSM and standard covariate adjustment. Additionally, those interested in a defense of PSM, including a direct response to King et al., may find further insights in Wan 2025 \[6\].

### Propensity Score Matching

To demonstrate Propenisty Scores in action, we will follow the work flow and example provided by Noah Greifer on what's called, Propensity Score Matching, using his MatchIt library.

```{r, include = F, warning = F}

# Libraries

library(tidyverse)      # dplyr, ggplot 
library(GGally)         # ggpairs 
library(MatchIt)        # matchit, lalonde data set 
library(readr)          # read csv 
library(dagitty)        # DAG 
library(DiagrammeR)     # Identity
library(tinytable)      # table
library(optmatch)
library(cobalt)         # loveplot
library(pwr)            # power analysis
```

In the tutorial, Greifer uses the Lalonde Data set, which is a subset of data sets from the National Supported Work Demonstration used by Dehejia and Wahba to evaluate propensity score matching methods. A table of the first few rows is provided below:

```{r, echo = F}

tinytable::tt(lalonde[1:8, 1:8], format = "markdown")
```

The workflow consistents of, selecting the type of effect to be estimated, selecting the target population to which the treatment effect is to generalize, selecting the matching algorithm, and selecting the covariates for which balance is required for an unbiased estimate of the treatment effect.

First, we check for initial imbalances in the lalonde data set (this is prior to any matching):

```{r, echo = F}

df = lalonde

# No matching

m.out0 = matchit(treat ~ age + educ + race + married + 
                    nodegree + re74 + re75,
                  data = df,
                  method = NULL,
                  distance = "glm")

# Checking balance prior to matching

summary(m.out0)
```

Looking at the Std. Mean Diff column, we notice quite a few covariate values that are far from 0 (values closer to 0 indicate good balance).

Now, we preform propensity score matching, deploying the 1:1 nearest neighbor algorithm. Looking again at the Std. Mean Diff column, we notice quite a few more covariates have scores closer to 0, indicating good balance.

```{r, echo = F}

# 1:1 NN PS matching w/o replacement

m.out1 = matchit(treat ~ age + educ + race + married + 
                    nodegree + re74 + re75,
                  data = df,
                  method = "nearest",
                  distance = "glm")

# Checking balance after NN matching

summary(m.out1, un = FALSE)
```

Additionally, we can view the matching using plots. The last plot being what's called a Love plot.

```{r, echo = F}

plot(m.out1, type = "jitter", interactive = FALSE)

plot(m.out1, type = "density", interactive = FALSE,
     which.xs = ~ age + married + re75)

plot(summary(m.out1))
```

```{r, include = F}

# Data Pre-Processing of champion stats and champion outcomes

## Pull in the data set:

champion_outcomes = readr::read_csv(
  file = "League_Dataset - League of Legends Champion Stats 12.1.csv"
)

champion_stat = readr::read_csv(
  file = "Lol_Champions.csv"
)

champion_outcomes = janitor::clean_names(champion_outcomes)

champion_stat = janitor::clean_names(champion_stat)

## NA's:

# sum(is.na(champion_outcomes) ) # 1

# sum(is.na(champion_stat) )     # 7

# nrow(champion_outcomes)        # 232

# nrow(champion_stat)            # 167

## Full Join data sets:

League = full_join(
  y = champion_outcomes,
  x = champion_stat,
  by = "name"
)

## Inspect for NA's:

# sum(is.na(League) ) # 141


## Filter out new champions with missing outcome data

League = League |> 
    dplyr::filter(
        !(name %in% c(
            "Bel'Veth",
            "Briar",
            "Hwei",
            "K'Sante",
            "Milio",
            "Naafiri",
            "Nunu",
            "Renata Glasc",
            "Smolder",
            "Zeri",
            "Nilah"
        )
      )
    )

## Check for missing values

# sum(is.na(League)) # 30

## Because there are still missing values, inspect which rows contain them

# view(
#   League |> 
#     filter(if_any(everything(), is.na))
# )

## Fill in missing values for Nunu from wiki league

League = League |>
  dplyr::mutate(
    class = ifelse(name == "Nunu & Willump" & is.na(class), "Tank", class),
    role.x = ifelse(name == "Nunu & Willump" & is.na(role.x), "JUNGLE", role.x),
    tier = ifelse(name == "Nunu & Willump" & is.na(tier), "A", tier),
    score = ifelse(name == "Nunu & Willump" & is.na(score), 55.47, score),
    trend = ifelse(name == "Nunu & Willump" & is.na(trend), 0.61, trend),
    win_percent = ifelse(name == "Nunu & Willump" & is.na(win_percent), "51.79%", win_percent),
    role_percent = ifelse(name == "Nunu & Willump" & is.na(role_percent), "89.52%", role_percent),
    pick_percent = ifelse(name == "Nunu & Willump" & is.na(pick_percent), "4.35%", pick_percent),
    ban_percent = ifelse(name == "Nunu & Willump" & is.na(ban_percent), "2.38%", ban_percent),
    kda = ifelse(name == "Nunu & Willump" & is.na(kda), 2.79, kda),
    role.y = ifelse(name == "Nunu & Willump" & is.na(role.y), "Jungle", role.y)
  )

## Fill in missing values

League = League |>
  dplyr::mutate(
    resourse_type = ifelse(name == "Dr. Mundo" & is.na(resourse_type), "Health", resourse_type),
    resourse_type = ifelse(name == "Garen" & is.na(resourse_type), 0, resourse_type),
    resourse_type = ifelse(name == "Katarina" & is.na(resourse_type), 0, resourse_type),
    resourse_type = ifelse(name == "Viego" & is.na(resourse_type), 0, resourse_type),
    resourse_type = ifelse(name == "Zac" & is.na(resourse_type), "Health", resourse_type),
    resourse_type = ifelse(name == "Riven" & is.na(resourse_type), 0, resourse_type),
    class = ifelse(name == "Lillia" & is.na(class), "Mage", class)
  )

## create a new field for Treatment Assignment. Tank = 1, Non-Tank = 0

League = League |> 
  dplyr::mutate(
    treatment = as.factor(ifelse(class == "Tank",1,0) )
  )

# convert strings to numerics

League$win_percent = as.numeric(sub("%","",League$win_percent) ) / 100

League$pick_percent = as.numeric(sub("%","",League$pick_percent) ) / 100
```

## Data Frame

Data for League of Legend Champion Features for Season 12 were extracted from two data sets that were joined on Champion name. Here we show the first few rows and columns of the joined data frame.

```{r, echo = F}

## Show data set

tinytable::tt(League[1:8, 1:35] )
```

## Methods

```{r, include = F}

# Note:
# - Estimand: $ATE = E[Y(i =1) - Y(i = 0)]$ where $Y(i = 1)$ = win rate if the champion were a Tank and $Y( i = 0)$ = win rate if the champion were not a Tank.
# 
# - Target Population: League of Legends Champions
# 
# - Matching Method Discussion
```

### A Priori Steps for Test:

We define a minimum effect size (MES) of 0.03, corresponding to a 3 percentage point difference in win rate, as the threshold of practical importance in champion balancing. We use a two-tailed t-test to compare matched Tank and non-Tank win rates, with α = 0.05. The null hypothesis ( $H_0 = \mu_{tank} - \mu_{non-tank} = 0$) assumes that the difference in win rates between Tank and non-Tank champions is 0. The alternative hypothesis posits a win rate difference greater than 3 percentage points between Tank and non-Tank champions.

#### Power Analysis:

Using an expected minimum effect size of 3 percentage points (MES = 0.03) and the observed standard deviation of win rates ( $\sigma$ = 0.01656), we calculated that a sample of just 6 champions would provide 80% power to detect such an effect using a two-tailed t-test with $\alpha$ = 0.05.

```{r, echo = F}

# Power Analysis:

# Minimum Effect Size: delta = 0.03

## sd:

sd = sd(League$win_percent) # 0.01656067

## Cohen's d: 

d = 0.03 / sd # 1.811521


## Test:

pwr::pwr.t.test(
  d = 1.811,
  power = 0.80,
  sig.level = 0.05,
  type = "two.sample",
  alternative = "two.sided"
) # n = 5.919827
```

## Assumptions:

We provide the reader with the causal mechanisms behind how Champion Class selection can cause win rate. Some Causal Assumptions we make are, Stable Unit Treatment Value, Conditional Ignorability, and Postivity.

```{r, echo = F}

# DAG:

causal_diagram1 <- dagitty::dagitty('dag {
  bb="0,0,1,1"
  Class [exposure, pos="0.5,0.7"]
  "Win Rate" [outcome, pos="0.5,0.3"]
  "movement speed" [pos="0.2,0.1"]
  "base armor" [pos="0.3,0.2"]
  "hp per lvl" [pos="0.4,0.1"]
  "base hp" [pos="0.7,0.2"]
  "hp regeneration" [pos="0.8,0.1"]
  "armor per lvl" [pos="0.3,0.4"]
  "resource type" [pos="0.6,0.4"]
  "magic resistance per lvl" [pos="0.4,0.5"]
  "attack speed" [pos="0.6,0.6"]
  "attack damage" [pos="0.7,0.5"]
  "base magic resistance" [pos="0.8,0.4"]
  "movement speed" -> Class
  "movement speed" -> "Win Rate"
  "base armor" -> Class
  "base armor" -> "Win Rate"
  "hp per lvl" -> Class
  "hp per lvl" -> "Win Rate"
  "base hp" -> Class
  "base hp" -> "Win Rate"
  "hp regeneration" -> Class
  "hp regeneration" -> "Win Rate"
  "armor per lvl" -> Class
  "armor per lvl" -> "Win Rate"
  "resource type" -> Class
  "resource type" -> "Win Rate"
  "magic resistance per lvl" -> Class
  "magic resistance per lvl" -> "Win Rate"
  "attack speed" -> Class
  "attack speed" -> "Win Rate"
  "attack damage" -> Class
  "attack damage" -> "Win Rate"
  "base magic resistance" -> Class
  "base magic resistance" -> "Win Rate"
}')

# Plot DAG

plot(causal_diagram1)
```

## Check Imbalances

```{r, echo = F}

# No matching; constructing a pre-match matchit object

m.out0 = MatchIt::matchit(treatment ~ mana_regeneration + base_hp + attack_range + movement_speed + base_mana + base_armor + resourse_type + hp_regeneration,
                 data = League,
                  method = NULL,
                  distance = "glm")

# Checking balance prior to matching

summary(m.out0)
```

```{r, echo = F}

# Final Matching Method: NN

m.out1 = MatchIt::matchit(treatment ~ magic_resistance_per_lvl +
                 base_armor + movement_speed + hp_per_lvl + base_hp + hp_regeneration + armor_per_lvl + resourse_type + attack_speed + attack_damage + base_magic_resistance,
                  data = League,
                  method = "nearest",
                  distance = "glm")


plot(m.out1, type = "jitter", interactive = FALSE)

plot(summary(m.out1))
```

```{r, include = F}

# Save the matched data: 

m.data = match_data(m.out1)

# head(m.data)

# nrow(m.data) # 56

# nrow(League) # 232
```

## Results

Under our pre-specified decision rule, with a test that had sufficient power to detect a minimum meaningful effect size of 3 percentage points, the observed test statistic fell within the acceptance region.. Therefore, in accordance with the above framework, we will behave as if the main hypothesis is true, that Tank-class assignment does not meaningfully affect win rate after adjusting for champion stats. Had Tanks truly conferred such an advantage, we should have observed a more extreme result. We will add these results to our background knowledge for future studies.

```{r, echo = F}

# Regression:

fit = lm(
  win_percent ~ treatment + magic_resistance_per_lvl +
                 base_armor + movement_speed + hp_per_lvl + base_hp + hp_regeneration + armor_per_lvl + resourse_type + attack_speed + attack_damage + base_magic_resistance,
  data = m.data)

## check summary of regression

# summary(fit)$coefficients["treatment1", "Estimate"]
# 0.00229587

# Removed covariates with match scores that were 0.

fit = lm(
  win_percent ~ treatment + magic_resistance_per_lvl +
                 base_armor + movement_speed + hp_per_lvl + base_hp + hp_regeneration + attack_speed + attack_damage + base_magic_resistance,
  data = m.data)

# summary(fit)$coefficients["treatment1", "Estimate"] 
# 0.002537454
```

```{r, echo = F}

# Extract treatment row only

treat_row = summary(fit)$coefficients["treatment1", , drop = FALSE]

# Round for presentation

treat_df = as.data.frame(treat_row)

treat_df = round(treat_df, 4)

# Add column for Critical Value

treat_df$`Critical t-value` = 2.018

# Rename columns

colnames(treat_df) = c("Estimate",
                       "Std. Error",
                       "t value",
                       "p-value",
                       "Critical t-value")

# Display table

tinytable::tt(treat_df)

```

## Limitations(In Progress)

There were some unobserved variables that could contribute to biasing my effect to some level. For example, data on Champion Items was not included and we believe that this variable would have a large positive effect specifically for tanks during certain seasons where Tank items are strong. Throughout the game, players need to purchase items for their champions to get stronger and there have been seasons where certain classes would benefit from item changes more than others. Another would be the Rank of the Win Rate. There are several Ranks within League of Legends. Given some of these limitations, Conditional Ignorability is harder to justify here.

## Conclusion(In Progress)

## Supplemental Information

### Data Sets

1.  Legends Stats: S12 data set: <https://www.kaggle.com/datasets/vivovinco/league-of-legends-champion-stats>

2.  League of Legends champions: <https://www.kaggle.com/datasets/cutedango/league-of-legends-champions>

3.  Missing Data that was filled in came frame Wiki League: <https://wiki.leagueoflegends.com/en-us/List_of_champions>

### EDA:

```{r, echo = F, warning = F}

# EDA:

## Isolate variables of interest

League1 = League |> 
  dplyr::select(
    treatment,
    mana_regeneration,
    base_hp,
    attack_range,
    movement_speed,
    base_mana,
    base_armor,
    resourse_type,
    hp_regeneration
  )

## Explore variables

GGally::ggpairs(
  League1,
  progress = T,
  )

## check for outliers and shape of distribution

hist(League$mana_regeneration)

hist(League$base_hp)

hist(League$attack_range)

hist(League$movement_speed)

hist(League$base_mana)

hist(League$hp_regeneration)

## treatment and outcome

League |> 
  ggplot2::ggplot(
    aes(
      x = treatment,
      y = win_percent
    )
  ) + geom_boxplot()


## density curve of treatment and outcome
## Note: For tanks, most of the data hangs around a 50% win rate.

League |> 
    ggplot2::ggplot(
        aes(
            fill = treatment,
            x = win_percent
        )
    ) +
    geom_density() 
```

#### Matching Methods

**Nearest Neighbor**

```{r, echo = F}

# 1:1 NN PS matching w/o replacement

m.out1 = MatchIt::matchit(treatment ~ magic_resistance_per_lvl +
                 base_armor + movement_speed + hp_per_lvl + base_hp + hp_regeneration + armor_per_lvl + resourse_type + attack_speed + attack_damage + base_magic_resistance,
                  data = League,
                  method = "nearest",
                  distance = "glm")

summary(m.out1, un = FALSE)

plot(m.out1, type = "jitter", interactive = FALSE)

plot(summary(m.out1))

# m.data = match_data(m.out1)

# head(m.data)
```

**Full Matching on probit**

```{r, echo = F}

# Full matching on a probit PS

m.out2 = MatchIt::matchit(treatment ~ magic_resistance_per_lvl + base_armor + movement_speed + hp_per_lvl + base_hp + hp_regeneration + armor_per_lvl + resourse_type + attack_speed + attack_damage + base_magic_resistance,
                  data = League,
                  method = "full",
                  distance = "glm",
                  link = "probit")

summary(m.out2, un = FALSE)

plot(m.out2, type = "jitter", interactive = FALSE)

plot(summary(m.out2))

# m.data2 = match_data(m.out2)

# head(m.data2)
```

**Optimal Matching on probit**

```{r, echo = F}

# Optimal matching on a probit PS

m.out3 = MatchIt::matchit(treatment ~ magic_resistance_per_lvl + base_armor + movement_speed + hp_per_lvl + base_hp + hp_regeneration + armor_per_lvl + resourse_type + attack_speed + attack_damage + base_magic_resistance,
                  data = League,
                  method = "optimal",
                  distance = "glm",
                  link = "probit")

summary(m.out3, un = FALSE)

plot(m.out3, type = "jitter", interactive = FALSE)

plot(summary(m.out3))

# m.data3 = match_data(m.out3)

# head(m.data3)
```

**Subclass matching on probit**

```{r, echo = F}

# Subclass matching on a probit PS

m.out3 = MatchIt::matchit(treatment ~ magic_resistance_per_lvl + base_armor + movement_speed + hp_per_lvl + base_hp + hp_regeneration + armor_per_lvl + resourse_type + attack_speed + attack_damage + base_magic_resistance,
                  data = League,
                  method = "subclass",
                  distance = "glm",
                  link = "probit")

summary(m.out3, un = FALSE)

plot(m.out3, type = "jitter", interactive = FALSE)

plot(summary(m.out3))

# m.data3 = match_data(m.out3)

# head(m.data3)
```

#### Diagnostics

```{r, echo = F}

## Diagnostic plots

fit = lm(win_percent ~ treatment,
          data = m.data)

plot(fit)

fit1 = lm(win_percent ~ treatment + mana_regeneration + mana_regeneration + base_hp + attack_range + movement_speed + base_mana + base_armor + resourse_type + hp_regeneration,
          data = m.data)

plot(fit1)

step(fit1)

summary(fit1)$r.squared
```

## Citations

1.  Rosenbaum, Paul R. *Design of Observational Studies*. Springer, 2020.

2.  Rosenbaum, Paul R. Observational Studies. Springer

3.  Rosenbaum, Paul R., and Donald B. Rubin. “The Central Role of the Propensity Score in Observational Studies for Causal Effects.” *Biometrika*, vol. 70, no. 1, Jan. 1983, pp. 41–55. https://doi.org/10.1093/biomet/70.1.41.

4.  King, Gary, and Richard Nielsen. “Why Propensity Scores Should Not Be Used for Matching.” *Political Analysis*, vol. 27, no. 4, 2019, gking.harvard.edu/publications/why-propensity-scores-should-not-be-used-formatching.

5.  Senn, Stephen, et al. “Stratification for the Propensity Score Compared with Linear Regression Techniques to Assess the Effect of Treatment or Exposure.” *Statistics in Medicine*, vol. 26, no. 30, 3 Dec. 2007, pp. 5529–5544, https://doi.org/10.1002/sim.3133. Accessed 11 Oct. 2020.

6.  Wan, Fei. “Propensity Score Matching: Should We Use It in Designing Observational Studies?” *BMC Medical Research Methodology*, vol. 25, no. 1, 29 Jan. 2025, https://doi.org/10.1186/s12874-025-02481-w.
